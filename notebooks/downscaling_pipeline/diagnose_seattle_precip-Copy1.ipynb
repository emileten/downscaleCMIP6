{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "51f7f33a-e232-4869-a825-c33d74a60a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xclim\n",
    "\n",
    "import xesmf\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from science_validation_manual import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import rhg_compute_tools.kubernetes as rhgk\n",
    "\n",
    "client, cluster = rhgk.get_micro_cluster()\n",
    "\n",
    "cluster.scale(100)\n",
    "cluster\n",
    "\n",
    "client.restart()\n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "# Playing with our raw ERA-5 data and regridding\n",
    "\n",
    "def lon360(lon180):\n",
    "    return ((360 + (lon180 % 360)) % 360)\n",
    "\n",
    "def lon180(lon360):\n",
    "    if (lon360 > 180.0):\n",
    "        return lon360 - 360.0\n",
    "    else:\n",
    "        return lon360\n",
    "\n",
    "# load ERA-5 versions \n",
    "# ERA-5 \"coarse\" and \"fine\" (both at 1/4 degree) used in downscaling\n",
    "pr_coarse_ref = read_gcs_zarr('gs://scratch-170cd6ec/91da8e47-b396-4360-b397-ece89f1b777e/e2e-miroc6-pr-8rn7f-2846959676/rechunked.zarr')\n",
    "pr_fine_ref = read_gcs_zarr('gs://scratch-170cd6ec/91da8e47-b396-4360-b397-ece89f1b777e/e2e-miroc6-pr-8rn7f-587431548/rechunked.zarr')\n",
    "# ERA-5 at regular Gaussian resolution, \"cleaned\" by renaming variable/dims \n",
    "pr_cleaned_ref = read_gcs_zarr('gs://clean-b1dbca25/reanalysis/ERA-5/F320/pr.1995-2015.F320.zarr')\n",
    "# ERA-5 at regular Gaussian resolution\n",
    "pr_raw_ref = read_gcs_zarr('gs://impactlab-data/climate/source_data/ERA-5/downscaling/pr.1994-2015.F320.v5.zarr')\n",
    "# define Seattle lat/lon \n",
    "target_lat = 47.608013\n",
    "target_lon = -122.335167 \n",
    "\n",
    "# now get Seattle timeseries from each of these ERA-5 versions.\n",
    "# two of the datasets have [0,360] ranging longitude, need to convert. \n",
    "pr_seattle_pipeline = pr_cleaned_ref['pr'].sel(lon=lon360(target_lon), lat=target_lat, method=\"nearest\").load()\n",
    "pr_seattle_pipeline_coarse = pr_coarse_ref['pr'].sel(lon=target_lon, lat=target_lat, method=\"nearest\").load()\n",
    "pr_seattle_pipeline_fine = pr_fine_ref['pr'].sel(lon=target_lon, lat=target_lat, method=\"nearest\").load()\n",
    "pr_seattle_pipeline_raw = pr_raw_ref['tp'].sel(longitude=lon360(target_lon), latitude=target_lat, method=\"nearest\").load()\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "pr_seattle_pipeline.groupby('time.year').sum().plot(label='our pipeline, cleaned')\n",
    "pr_seattle_pipeline_raw.groupby('time.year').sum().plot(label='our pipeline, raw', linestyle=':')\n",
    "pr_seattle_pipeline_coarse.groupby('time.year').sum().plot(label='our pipeline, coarse')\n",
    "pr_seattle_pipeline_fine.groupby('time.year').sum().plot(label='our pipeline, fine')\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.ylabel('precip (mm)')\n",
    "plt.title('Seattle annual precip, longitude corrected for raw & cleaned')\n",
    "\n",
    "dict_of_da = {'cleaned':pr_seattle_pipeline, \n",
    "              'regridded_coarse':pr_seattle_pipeline_coarse,\n",
    "              'regridded_fine':pr_seattle_pipeline_fine}\n",
    "\n",
    "for key, da in dict_of_da.items():\n",
    "    print(key)\n",
    "    res = {\n",
    "        'zeros_pct': da.where(da>=0.254).isnull().sum().values.item()/len(da.time.values),\n",
    "        'min': da.min().compute().values.item(),\n",
    "        'q1': da.quantile(0.01).compute().values.item(),\n",
    "        'q10': da.quantile(0.10).compute().values.item(),\n",
    "        'q50': da.quantile(0.5).compute().values.item(),\n",
    "        'q90': da.quantile(0.10).compute().values.item(),\n",
    "        'q99': da.quantile(0.99).compute().values.item(),\n",
    "        'max': da.max().compute().values.item(),\n",
    "        'mean': da.mean().compute().values.item(),\n",
    "        'year_sum_min' : da.groupby('time.year').sum().min().compute().values.item(),\n",
    "        'year_sum_mean' : da.groupby('time.year').sum().mean().compute().values.item(),\n",
    "        'year_sum_max' : da.groupby('time.year').sum().max().compute().values.item()\n",
    "    }\n",
    "    for r in res:\n",
    "        res[r] = round(res[r], 3)\n",
    "    print(res)\n",
    "\n",
    "import seaborn\n",
    "pl = seaborn.displot(dict_of_da, bins=500)\n",
    "pl.set(xlim=(0,10))\n",
    "\n",
    "pl = seaborn.displot(dict_of_da, kind='kde')\n",
    "pl.set(xlim=(0,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31e440-f0e0-461d-b84a-79aaca37c524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
